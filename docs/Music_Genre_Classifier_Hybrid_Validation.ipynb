{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEX_PUPCBSZA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow.compat.v1 as tfv1\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4BWpDkhwoV7i",
    "outputId": "e0ccbb45-c5c2-40d9-e880-86bdc6b24f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NSl5vaDn1fAP",
    "outputId": "7117312f-6f71-48dd-b961-7a39f913d437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/.shortcut-targets-by-id/1Y2mRkkRB6wyTJ1-1zFboT6i8X4wUbIq6/CS467_shared\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/Colab Notebooks/OSU/CS467_shared'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWIQTfmWtjj_"
   },
   "outputs": [],
   "source": [
    "#declare hyperparameters \n",
    "BATCH_SIZE = 32 \n",
    "NUM_EPOCHS = 20 \n",
    "\n",
    "#and k-fold params and per-fold containers\n",
    "num_folds = 10\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "#and other globals\n",
    "IMG_PIXELS = 67000\n",
    "img_width = 335 \n",
    "img_height = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATcZP-VqxOEz"
   },
   "outputs": [],
   "source": [
    "label_strings = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8u09IdXjcSIb"
   },
   "outputs": [],
   "source": [
    "#convert GTZAN to a tensorflow dataset. This skips the steps of importing all the images,\n",
    "#then converting them thus saving on memory\n",
    "GTZAN_dataset = tf.data.experimental.load(\n",
    "    './Data/GTZAN_dataset',\n",
    "    (tf.TensorSpec(shape=(IMG_PIXELS,), dtype=tf.int32, name=None),\n",
    "     tf.TensorSpec(shape=(), dtype=tf.int32, name=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4MAkaYfgA5V"
   },
   "outputs": [],
   "source": [
    "#build images and labels array from \n",
    "images = []\n",
    "labels = []\n",
    "for x, y in GTZAN_dataset:\n",
    "  images.append(x.numpy())\n",
    "  labels.append(y.numpy())\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7BS3iTD7nXv"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1 and reshape\n",
    "images = images / 255.0\n",
    "images = images.reshape(images.shape[0], img_height, img_width, 1)\n",
    "\n",
    "# one hot encode labels\n",
    "labels = tf.keras.utils.to_categorical(labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "aFw3ClLPM5Fm",
    "outputId": "9c929a57-9589-4459-dc5e-b3764632e792"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>zero_crossing_rate_mean</th>\n",
       "      <th>zero_crossing_rate_var</th>\n",
       "      <th>harmony_mean</th>\n",
       "      <th>harmony_var</th>\n",
       "      <th>perceptr_mean</th>\n",
       "      <th>perceptr_var</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mfcc1_mean</th>\n",
       "      <th>mfcc1_var</th>\n",
       "      <th>mfcc2_mean</th>\n",
       "      <th>mfcc2_var</th>\n",
       "      <th>mfcc3_mean</th>\n",
       "      <th>mfcc3_var</th>\n",
       "      <th>mfcc4_mean</th>\n",
       "      <th>mfcc4_var</th>\n",
       "      <th>mfcc5_mean</th>\n",
       "      <th>mfcc5_var</th>\n",
       "      <th>mfcc6_mean</th>\n",
       "      <th>mfcc6_var</th>\n",
       "      <th>mfcc7_mean</th>\n",
       "      <th>mfcc7_var</th>\n",
       "      <th>mfcc8_mean</th>\n",
       "      <th>mfcc8_var</th>\n",
       "      <th>mfcc9_mean</th>\n",
       "      <th>mfcc9_var</th>\n",
       "      <th>mfcc10_mean</th>\n",
       "      <th>mfcc10_var</th>\n",
       "      <th>mfcc11_mean</th>\n",
       "      <th>mfcc11_var</th>\n",
       "      <th>mfcc12_mean</th>\n",
       "      <th>mfcc12_var</th>\n",
       "      <th>mfcc13_mean</th>\n",
       "      <th>mfcc13_var</th>\n",
       "      <th>mfcc14_mean</th>\n",
       "      <th>mfcc14_var</th>\n",
       "      <th>mfcc15_mean</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>3805.839606</td>\n",
       "      <td>9.015054e+05</td>\n",
       "      <td>0.083045</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-4.529724e-05</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>-113.570648</td>\n",
       "      <td>2564.207520</td>\n",
       "      <td>121.571793</td>\n",
       "      <td>295.913818</td>\n",
       "      <td>-19.168142</td>\n",
       "      <td>235.574432</td>\n",
       "      <td>42.366421</td>\n",
       "      <td>151.106873</td>\n",
       "      <td>-6.364664</td>\n",
       "      <td>167.934799</td>\n",
       "      <td>18.623499</td>\n",
       "      <td>89.180840</td>\n",
       "      <td>-13.704891</td>\n",
       "      <td>67.660492</td>\n",
       "      <td>15.343150</td>\n",
       "      <td>68.932579</td>\n",
       "      <td>-12.274110</td>\n",
       "      <td>82.204201</td>\n",
       "      <td>10.976572</td>\n",
       "      <td>63.386311</td>\n",
       "      <td>-8.326573</td>\n",
       "      <td>61.773094</td>\n",
       "      <td>8.803792</td>\n",
       "      <td>51.244125</td>\n",
       "      <td>-3.672300</td>\n",
       "      <td>41.217415</td>\n",
       "      <td>5.747995</td>\n",
       "      <td>40.554478</td>\n",
       "      <td>-5.162882</td>\n",
       "      <td>49.775421</td>\n",
       "      <td>0.752740</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>3550.522098</td>\n",
       "      <td>2.977893e+06</td>\n",
       "      <td>0.056040</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>1.395807e-04</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>67.999589</td>\n",
       "      <td>-207.501694</td>\n",
       "      <td>7764.555176</td>\n",
       "      <td>123.991264</td>\n",
       "      <td>560.259949</td>\n",
       "      <td>8.955127</td>\n",
       "      <td>572.810913</td>\n",
       "      <td>35.877647</td>\n",
       "      <td>264.506104</td>\n",
       "      <td>2.907320</td>\n",
       "      <td>279.932922</td>\n",
       "      <td>21.510466</td>\n",
       "      <td>156.477097</td>\n",
       "      <td>-8.560436</td>\n",
       "      <td>200.849182</td>\n",
       "      <td>23.370686</td>\n",
       "      <td>142.555954</td>\n",
       "      <td>-10.099661</td>\n",
       "      <td>166.108521</td>\n",
       "      <td>11.900497</td>\n",
       "      <td>104.358612</td>\n",
       "      <td>-5.555639</td>\n",
       "      <td>105.173630</td>\n",
       "      <td>5.376327</td>\n",
       "      <td>96.197212</td>\n",
       "      <td>-2.231760</td>\n",
       "      <td>64.914291</td>\n",
       "      <td>4.220140</td>\n",
       "      <td>73.152534</td>\n",
       "      <td>-6.012148</td>\n",
       "      <td>52.422142</td>\n",
       "      <td>0.927998</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>3042.260232</td>\n",
       "      <td>7.840345e+05</td>\n",
       "      <td>0.076291</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>2.105576e-06</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>161.499023</td>\n",
       "      <td>-90.722595</td>\n",
       "      <td>3319.044922</td>\n",
       "      <td>140.446304</td>\n",
       "      <td>508.765045</td>\n",
       "      <td>-29.093889</td>\n",
       "      <td>411.781219</td>\n",
       "      <td>31.684334</td>\n",
       "      <td>144.090317</td>\n",
       "      <td>-13.984504</td>\n",
       "      <td>155.493759</td>\n",
       "      <td>25.764742</td>\n",
       "      <td>74.548401</td>\n",
       "      <td>-13.664875</td>\n",
       "      <td>106.981827</td>\n",
       "      <td>11.639934</td>\n",
       "      <td>106.574875</td>\n",
       "      <td>-11.783643</td>\n",
       "      <td>65.447945</td>\n",
       "      <td>9.718760</td>\n",
       "      <td>67.908859</td>\n",
       "      <td>-13.133803</td>\n",
       "      <td>57.781425</td>\n",
       "      <td>5.791199</td>\n",
       "      <td>64.480209</td>\n",
       "      <td>-8.907628</td>\n",
       "      <td>60.385151</td>\n",
       "      <td>-1.077000</td>\n",
       "      <td>57.711136</td>\n",
       "      <td>-9.229274</td>\n",
       "      <td>36.580986</td>\n",
       "      <td>2.451690</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>2184.745799</td>\n",
       "      <td>1.493194e+06</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>4.583644e-07</td>\n",
       "      <td>0.019054</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>63.024009</td>\n",
       "      <td>-199.544205</td>\n",
       "      <td>5507.517090</td>\n",
       "      <td>150.090897</td>\n",
       "      <td>456.505402</td>\n",
       "      <td>5.662678</td>\n",
       "      <td>257.161163</td>\n",
       "      <td>26.859079</td>\n",
       "      <td>158.267303</td>\n",
       "      <td>1.771399</td>\n",
       "      <td>268.034393</td>\n",
       "      <td>14.234031</td>\n",
       "      <td>126.794128</td>\n",
       "      <td>-4.832006</td>\n",
       "      <td>155.912079</td>\n",
       "      <td>9.286494</td>\n",
       "      <td>81.273743</td>\n",
       "      <td>-0.759186</td>\n",
       "      <td>92.114090</td>\n",
       "      <td>8.137607</td>\n",
       "      <td>71.314079</td>\n",
       "      <td>-3.200653</td>\n",
       "      <td>110.236687</td>\n",
       "      <td>6.079319</td>\n",
       "      <td>48.251999</td>\n",
       "      <td>-2.480174</td>\n",
       "      <td>56.799400</td>\n",
       "      <td>-1.079305</td>\n",
       "      <td>62.289902</td>\n",
       "      <td>-2.870789</td>\n",
       "      <td>51.651592</td>\n",
       "      <td>0.780874</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>3579.757627</td>\n",
       "      <td>1.572978e+06</td>\n",
       "      <td>0.101461</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>-1.756129e-05</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>-160.337708</td>\n",
       "      <td>5195.291992</td>\n",
       "      <td>126.219635</td>\n",
       "      <td>853.784729</td>\n",
       "      <td>-35.587811</td>\n",
       "      <td>333.792938</td>\n",
       "      <td>22.148071</td>\n",
       "      <td>193.456100</td>\n",
       "      <td>-32.478600</td>\n",
       "      <td>336.276825</td>\n",
       "      <td>10.852294</td>\n",
       "      <td>134.831573</td>\n",
       "      <td>-23.352329</td>\n",
       "      <td>93.257095</td>\n",
       "      <td>0.498434</td>\n",
       "      <td>124.672127</td>\n",
       "      <td>-11.793437</td>\n",
       "      <td>130.073349</td>\n",
       "      <td>1.207256</td>\n",
       "      <td>99.675575</td>\n",
       "      <td>-13.088418</td>\n",
       "      <td>80.254066</td>\n",
       "      <td>-2.813867</td>\n",
       "      <td>86.430626</td>\n",
       "      <td>-6.933385</td>\n",
       "      <td>89.555443</td>\n",
       "      <td>-7.552725</td>\n",
       "      <td>70.943336</td>\n",
       "      <td>-9.164666</td>\n",
       "      <td>75.793404</td>\n",
       "      <td>-4.520576</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  ...  mfcc20_mean  mfcc20_var  label\n",
       "0  blues.00000.wav  661794          0.350088  ...     1.221291   46.936035  blues\n",
       "1  blues.00001.wav  661794          0.340914  ...     0.531217   45.786282  blues\n",
       "2  blues.00002.wav  661794          0.363637  ...    -2.231258   30.573025  blues\n",
       "3  blues.00003.wav  661794          0.404785  ...    -3.407448   31.949339  blues\n",
       "4  blues.00004.wav  661794          0.308526  ...   -11.703234   55.195160  blues\n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing feature dataset\n",
    "data = pd.read_csv('./Data/features_30_sec.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xytFMQtNX_z"
   },
   "outputs": [],
   "source": [
    "#build our array of feat labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "feat_labels = []\n",
    "for x in genre_list:\n",
    "  feat_labels.append(label_strings.index(x))\n",
    "\n",
    "feat_labels = np.array(feat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXGUMyzt0Q0C"
   },
   "outputs": [],
   "source": [
    "#clean up the \n",
    "data = data.drop(['filename'],axis=1)\n",
    "scaler = StandardScaler()\n",
    "feat_values = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "\n",
    "#one hot encode the new labels \n",
    "feat_labels = tf.keras.utils.to_categorical(feat_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we get to the K-fold bits.\n",
    "Our k-fold harness only understands 2 dimsnational arrays. The features dataframe fits this stipualtion, but our images array does not. Moreover, we can only pass a single data object to the split function that parses the data into randomly allocated train and test sets. Therefore we need to reshape the image files into a single dimensional array, then append those onto our features, but only temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "39zFBlwI8_2i",
    "outputId": "f5f3a142-37c8-4b23-bfca-45dddae0002b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 58)\n",
      "(999, 200, 335, 1)\n",
      "(999, 67000)\n",
      "(999, 67058)\n"
     ]
    }
   ],
   "source": [
    "print(feat_values.shape)\n",
    "print(images.shape)\n",
    "\n",
    "flat_images = images\n",
    "flat_images = flat_images.flatten().reshape(999, 67000)\n",
    "print(flat_images.shape)\n",
    "\n",
    "data_master = np.concatenate((feat_values, flat_images), axis=1)\n",
    "\n",
    "print(data_master.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JsqEba9aCl2e",
    "outputId": "3b4ea273-e9ca-4a40-8b97-beccd7d8f686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 2.0406 - accuracy: 0.3070\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 1.0467 - accuracy: 0.6452\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.5593 - accuracy: 0.8354\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.3341 - accuracy: 0.9155\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.1772 - accuracy: 0.9689\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.1010 - accuracy: 0.9878\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0470 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.4755 - accuracy: 0.8300\n",
      "Score for fold 1: loss of 0.4755220413208008;   accuracy of 82.99999833106995%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.1062 - accuracy: 0.3092\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 0.9862 - accuracy: 0.6707\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.6464 - accuracy: 0.8087\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.3430 - accuracy: 0.9199\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.1728 - accuracy: 0.9700\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.1137 - accuracy: 0.9844\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0499 - accuracy: 0.9989\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.6848 - accuracy: 0.8600\n",
      "Score for fold 2: loss of 0.684782862663269;   accuracy of 86.00000143051147%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 1.9873 - accuracy: 0.3281\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 1.0075 - accuracy: 0.6674\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.5509 - accuracy: 0.8420\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.3461 - accuracy: 0.8921\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1437 - accuracy: 0.9889\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0656 - accuracy: 0.9956\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.3787 - accuracy: 0.8400\n",
      "Score for fold 3: loss of 0.3787446618080139;   accuracy of 83.99999737739563%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.1327 - accuracy: 0.3215\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.9651 - accuracy: 0.6908\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.5964 - accuracy: 0.8031\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.3542 - accuracy: 0.9066\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1663 - accuracy: 0.9800\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0980 - accuracy: 0.9933\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1611 - accuracy: 0.9566\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 30ms/step - loss: 0.0636 - accuracy: 0.9944\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.3693 - accuracy: 0.8500\n",
      "Score for fold 4: loss of 0.369299978017807;   accuracy of 85.00000238418579%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.0746 - accuracy: 0.3003\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 1.0211 - accuracy: 0.6585\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.6842 - accuracy: 0.7998\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.3525 - accuracy: 0.9177\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.2057 - accuracy: 0.9566\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1136 - accuracy: 0.9855\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0524 - accuracy: 0.9989\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.8234 - accuracy: 0.7600\n",
      "Score for fold 5: loss of 0.8233709931373596;   accuracy of 75.99999904632568%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.0040 - accuracy: 0.3092\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 1.0156 - accuracy: 0.6240\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.5488 - accuracy: 0.8265\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.2819 - accuracy: 0.9422\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1198 - accuracy: 0.9911\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0758 - accuracy: 0.9956\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0486 - accuracy: 0.9967\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.8033 - accuracy: 0.7300\n",
      "Score for fold 6: loss of 0.8033146858215332;   accuracy of 73.00000190734863%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.1602 - accuracy: 0.3215\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 1.0223 - accuracy: 0.6552\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.6077 - accuracy: 0.8165\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.3357 - accuracy: 0.9255\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.1847 - accuracy: 0.9666\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0923 - accuracy: 0.9911\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0510 - accuracy: 0.9978\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.5938 - accuracy: 0.8700\n",
      "Score for fold 7: loss of 0.5937854051589966;   accuracy of 87.00000047683716%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.0402 - accuracy: 0.3059\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.9903 - accuracy: 0.6541\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.6138 - accuracy: 0.7964\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.3262 - accuracy: 0.9132\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1730 - accuracy: 0.9766\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1066 - accuracy: 0.9900\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0541 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.7821 - accuracy: 0.7600\n",
      "Score for fold 8: loss of 0.7821199893951416;   accuracy of 75.99999904632568%\n",
      "(100, 10)\n",
      "(899, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.0892 - accuracy: 0.3037\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 1.0733 - accuracy: 0.6574\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.6260 - accuracy: 0.8242\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.3351 - accuracy: 0.9277\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1749 - accuracy: 0.9778\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0898 - accuracy: 0.9944\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0582 - accuracy: 0.9989\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0427 - accuracy: 0.9989\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.7115 - accuracy: 0.7400\n",
      "Score for fold 9: loss of 0.7115135788917542;   accuracy of 74.00000095367432%\n",
      "(99, 10)\n",
      "(900, 10)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 2.1289 - accuracy: 0.3178\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 1.0053 - accuracy: 0.6911\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.5839 - accuracy: 0.8256\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.3553 - accuracy: 0.9056\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.1545 - accuracy: 0.9800\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0833 - accuracy: 0.9944\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0487 - accuracy: 0.9989\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 29ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "4/4 - 0s - loss: 0.6922 - accuracy: 0.7778\n",
      "Score for fold 10: loss of 0.6921655535697937;   accuracy of 77.77777910232544%\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation test harness\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for train, test in kf.split(data_master, labels):\n",
    "  #reshape our newly split data back to their orginal shapes\n",
    "  k_train_images = data_master[train][:,58:67058]\n",
    "  k_train_images = k_train_images.reshape(\n",
    "      k_train_images.shape[0], img_height, img_width, 1)\n",
    "  k_train_feats_values = data_master[train][:, :58]\n",
    "  k_test_images = data_master[test][:,58:67058]\n",
    "  k_test_images = k_test_images.reshape(\n",
    "      k_test_images.shape[0], img_height, img_width, 1)\n",
    "  k_test_feats_values = data_master[test][:, :58]\n",
    "\n",
    "  #the rest looks mostly like the hybrid model Josh built for us.\n",
    "\n",
    "  # feature layers\n",
    "  feat_input = keras.Input(shape=(k_feats_values.shape[1],), name='feat_input')\n",
    "  x = keras.layers.Dense(256, activation='relu')(feat_input)\n",
    "  x = keras.layers.Dense(128, activation='relu')(x)\n",
    "  feat_layers = keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "  # image convolutional layers\n",
    "  img_input = keras.Input(shape=(img_height, img_width, 1), name=\"img_input\")\n",
    "  x = keras.layers.Conv2D(32, kernel_size=(5, 5), activation='relu')(img_input)\n",
    "  x = keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(4,4))(x)\n",
    "  x = keras.layers.Dropout(0.25)(x)\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  img_layers = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "  # concatenate img layers with feature layers and define output layer\n",
    "  combined = keras.layers.concatenate([img_layers, feat_layers])\n",
    "  out_layer = keras.layers.Dense(10, activation='softmax')(combined)\n",
    "\n",
    "  # define model with both image and feature inputs\n",
    "  model = keras.Model(inputs=[feat_input, img_input], outputs=out_layer)\n",
    "\n",
    "  # compile model\n",
    "  model.compile(optimizer='adam',\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # fit model\n",
    "  history = model.fit(x=[k_train_feats_values, k_train_images], y=labels[train],  \n",
    "                    batch_size=BATCH_SIZE, epochs=NUM_EPOCHS) \n",
    "\n",
    "  # Generate generalization metrics and append to respective containers\n",
    "  scores = model.evaluate([k_test_feats_values, k_test_images], \n",
    "                          y=labels[test], verbose=2)\n",
    "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]};\\\n",
    "   {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "  acc_per_fold.append(scores[1] * 100)\n",
    "  loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "b04MhPPutoSo",
    "outputId": "f7b16a06-540c-4efd-ab28-96b01f49ce9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.49381014704704285 - Accuracy: 82.99999833106995%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.5414174795150757 - Accuracy: 80.0000011920929%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.689606785774231 - Accuracy: 83.99999737739563%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.5572614073753357 - Accuracy: 81.00000023841858%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.5173542499542236 - Accuracy: 81.00000023841858%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 0.6691000461578369 - Accuracy: 81.99999928474426%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 0.7367213368415833 - Accuracy: 72.00000286102295%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 1.0287184715270996 - Accuracy: 77.99999713897705%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 0.570132315158844 - Accuracy: 81.99999928474426%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 0.4056760370731354 - Accuracy: 84.84848737716675%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 11 - Loss: 0.4755220413208008 - Accuracy: 82.99999833106995%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 12 - Loss: 0.684782862663269 - Accuracy: 86.00000143051147%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 13 - Loss: 0.3787446618080139 - Accuracy: 83.99999737739563%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 14 - Loss: 0.369299978017807 - Accuracy: 85.00000238418579%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 15 - Loss: 0.8233709931373596 - Accuracy: 75.99999904632568%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 16 - Loss: 0.8033146858215332 - Accuracy: 73.00000190734863%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 17 - Loss: 0.5937854051589966 - Accuracy: 87.00000047683716%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 18 - Loss: 0.7821199893951416 - Accuracy: 75.99999904632568%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 19 - Loss: 0.7115135788917542 - Accuracy: 74.00000095367432%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 20 - Loss: 0.6921655535697937 - Accuracy: 77.77777910232544%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 80.48131316900253 (+- 4.352084396801198)\n",
      "> Loss: 0.6262209013104438\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_JW8sBjo4TV"
   },
   "source": [
    "An accuracy of 76% - 84% is pretty dang good! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Music Genre Classification_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
